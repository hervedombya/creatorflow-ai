# file: backend/main.py
import os
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from openai import OpenAI
from google import genai
from io import BytesIO
from PIL import Image
import base64
from fastapi.middleware.cors import CORSMiddleware

from google import genai

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if not GEMINI_API_KEY:
    raise ValueError("GEMINI_API_KEY is not set in environment variables")

gemini_client = genai.Client(api_key=GEMINI_API_KEY)



# Load environment variables from .env file
load_dotenv()


# ====== CONFIG ======
FEATHERLESS_API_KEY = os.getenv("FEATHERLESS_API_KEY")
FEATHERLESS_MODEL = "featherless_ai/meta-llama/Meta-Llama-3.1-70B-Instruct"
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if not FEATHERLESS_API_KEY:
    raise ValueError("FEATHERLESS_API_KEY is not set in environment variables")

if not GEMINI_API_KEY:
    raise ValueError("GEMINI_API_KEY is not set in environment variables")

# Client Featherless (API compatible OpenAI)
featherless_client = OpenAI(
    api_key=FEATHERLESS_API_KEY,
    base_url="https://api.featherless.ai/v1"
)

# Gemini client
genai.configure(api_key=GEMINI_API_KEY)

app = FastAPI(
    title="CreatorFlow AI - Backend",
    description="API for generating optimized prompts and images",
    version="1.0.0"
)


# CORS for frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",
        "https://*.vercel.app",
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)



# ====== MODELS ======
class PromptInput(BaseModel):
    user_text: str
    image_description: str = ""
    style: str = "cinematic"
    mood: str = "epic"



class GenerationResponse(BaseModel):
    master_prompt: str
    image_url: str



class AnalyzeStyleInput(BaseModel):
    text_samples: list[str]



class StyleProfile(BaseModel):
    tone: str
    vibe_keywords: list[str]
    writing_style: str



# ====== HELPER FUNCTIONS ======
def build_master_prompt(user_text: str) -> str:
    """
    Calls Featherless to transform user input into an optimized image prompt.
    """
    system_message = (
        "Tu es un expert en prompt engineering pour modèles d'images "
        "(Flux, SDXL, DALL-E). Tu génères UN SEUL prompt ultra clair, en anglais, "
        "optimisé pour le text-to-image. Tu ne rajoutes aucun commentaire autour."
    )


    user_message = f"""
User text: {user_text}
Return a single, clean text-to-image prompt in English. No quotes, no extra text.
"""


    completion = featherless_client.chat.completions.create(
        model=FEATHERLESS_MODEL,
        messages=[
            {"role": "system", "content": system_message},
            {"role": "user", "content": user_message},
        ],
        temperature=0.7,
        max_tokens=300,
    )


    master_prompt = completion.choices[0].message.content.strip()
    return master_prompt



def generate_image_from_prompt(prompt: str, image_bytes: bytes) -> str:
    """
    Envoie l'image input + le master prompt à Gemini et retourne l'image éditée en base64.
    """
    try:
        # Appel au modèle d'édition image
        response = gemini_client.models.generate_images(
            model="gemini-2.5-flash-image-preview",
            prompt=prompt,
            image=image_bytes,
        )

        if response.generated_images and len(response.generated_images) > 0:
            generated_image = response.generated_images[0].image

            buffered = BytesIO()
            generated_image.save(buffered, format="PNG")
            img_base64 = base64.b64encode(buffered.getvalue()).decode()

            return f"data:image/png;base64,{img_base64}"

        raise HTTPException(status_code=500, detail="No image generated by Gemini")

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Failed to generate image: {str(e)}"
        )





# ====== ROUTES ======
@app.get("/")
def root():
    return {"status": "ok", "message": "CreatorFlow AI - Backend API"}



@app.get("/health")
def health_check():
    return {"status": "healthy"}



@app.post("/api/v1/generate", response_model=GenerationResponse)
def generate_endpoint(payload: PromptInput):
    """Generate image from user input."""
    master_prompt = build_master_prompt(
        user_text=payload.user_text,
    )
    
    image_url = generate_image_from_prompt(master_prompt)


    return GenerationResponse(
        master_prompt=master_prompt,
        image_url=image_url,
    )

if __name__ == "__main__":
    prompt = build_master_prompt("Ajoute moi une casquette gucci")
    print("MASTER PROMPT:\n", prompt)

    with open("input.png", "rb") as f:
        image_bytes = f.read()

    image_data_url = generate_image_from_prompt(prompt, image_bytes)
    print("\nIMAGE DATA URL (troncée):\n", image_data_url[:200], "...")

    header, b64data = image_data_url.split(",", 1)
    img_bytes = base64.b64decode(b64data)

    with open("test_gucci.png", "wb") as f:
        f.write(img_bytes)

    print("\nImage sauvegardée en test_gucci.png")

